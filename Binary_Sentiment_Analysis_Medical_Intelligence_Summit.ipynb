{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Sentiment Analysis - Medical Intelligence Summit.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIz2j4t-OAS1",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment analysis\n",
        "#### Louis Ehwerhemuepha, PhD and Afnan (Nana) Alqahtani, MS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obOtow2K-TSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer as ps\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras import layers, losses\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from wordcloud import WordCloud\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsvYEHeRDW8_",
        "colab_type": "text"
      },
      "source": [
        "Retrieve Data for Sentiment Analysis from Louis' Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKKOUBgwx8vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get data from Louis' github repository\n",
        "! git clone https://github.com/ehwerhemuepha/sentimentanalysis.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bj7zEhN-SCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls sentimentanalysis # list cwd contents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAZq4xOTySSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = pd.read_csv('sentimentanalysis/AmazonProductReviewKaggle.txt',sep='\\t', encoding='ISO-8859-1', names = ['id', 'rating', 'reviewtext', 'reviewtitle'],skiprows=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFnA7_GSAJ72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K3qjbuyEdzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsJqIn1B82V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the review texts\n",
        "reviewsTitle=d['reviewtitle'].values\n",
        "reviewsText=d['reviewtext'].values\n",
        "reviews = [str(reviewsText[i]).lower() + ' ' + str(reviewsTitle[i]).lower() for i in range(len(reviewsTitle))]\n",
        "\n",
        "# remove noise\n",
        "reviews = [re.sub(\"(<.*?>)\", \"\", elem).strip() for elem in reviews] #HTML tags\n",
        "reviews = [re.sub(\"(\\W|\\d+)\", \" \", elem).strip() for elem in reviews] # spaces and digits\n",
        "\n",
        "# perform stemming -- words such as (run, running, ran, runs) -> run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8NjfWc80VdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "rating=[1 if elem>3 else 0 for elem in d['rating'].values] # 1 a rating of 4 or 5; 0 otherwise\n",
        "rating_categorical = to_categorical(rating) # for multi-label predictionn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-zHHFzjQ--g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min(rating), max(rating)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMBBPprBMY21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews[0:9], rating[0:9], rating_categorical[0:9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vihJiQUL7NiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optionally perform stemming -- improved accuracy though somewhat imperfect\n",
        "# \n",
        "stemmer = ps()\n",
        "def stemlist(word_list):\n",
        "  return ' '.join([stemmer.stem(word=word) for word in word_list.split()])\n",
        "\n",
        "reviews = [stemlist(elem) for elem in reviews]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F_4WQFYMaLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.shape, len(reviews), len(rating)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlcq7w6SWpv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews[0:9], rating[0:9], rating_categorical[0:9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t37fz2sUXp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word frequencies via wordcloud\n",
        "\n",
        "complete_text = ''\n",
        "for elem in reviews:\n",
        "  complete_text += elem\n",
        "  \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "wc = WordCloud(max_words=200, height = 1000, width = 1000, \n",
        "              background_color = 'white').generate(complete_text)\n",
        "fig = plt.figure(1, figsize=(10,10))\n",
        "\n",
        "plt.imshow(wc)\n",
        "plt.show()\n",
        "complete_text=''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obu_zmeADrAl",
        "colab_type": "text"
      },
      "source": [
        "Split your data into training and test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyDLX_obCF6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(reviews, rating_categorical, test_size=0.20, random_state=727)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBz1_HSnbMdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain[0:4], ytrain[0:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m443mHVvDs3v",
        "colab_type": "text"
      },
      "source": [
        "Tokenization\n",
        "\n",
        "Tokenization is the breaking up of sentences into tokens (aka words, in English). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjTIihv2CLBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=2000) # get a count of all tokens and use the 1000 most common only\n",
        "tokenizer.fit_on_texts(xtrain)\n",
        "xtrain = tokenizer.texts_to_sequences(xtrain)\n",
        "xtest = tokenizer.texts_to_sequences(xtest)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # plus index 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFiuc14EG3AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain[0], xtest[0], vocab_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC8wpON-JDC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(xtrain) , len(xtest), len(xtrain) + len(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_h7PjtAIqt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(tokenizer.word_counts.items())[0:19], len(tokenizer.word_counts) # tokens and token frequencies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzdLMPB0DwXO",
        "colab_type": "text"
      },
      "source": [
        "Pad in order to ensure that all sequences have the same length\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGpuVgjcCRkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100 # assumes the first 100 words are the most important in the review (especially in good ones) and that most review may have less than 50 workds == adjust too see effect on accuracy if any\n",
        "xtrain = pad_sequences(xtrain, padding='pre', maxlen=maxlen) \n",
        "xtest = pad_sequences(xtest, padding='pre', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLIfGTQ_JTwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain[0], xtest[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFH-y-uOET9-",
        "colab_type": "text"
      },
      "source": [
        "Build model and get model performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6CtxBmJRsGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN model\n",
        "rnnmodel = Sequential()\n",
        "rnnmodel.add(layers.Embedding(input_dim=vocab_size, output_dim=50, input_length=maxlen))\n",
        "# rnnmodel.add(layers.Embedding(50, 10))\n",
        "rnnmodel.add(layers.SimpleRNN(units=50))\n",
        "rnnmodel.add(layers.Dense(2, activation='softmax'))\n",
        "rnnmodel.compile(optimizer='adam',\n",
        "              loss=losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "rnnmodel.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJZCB6AEbKft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 256\n",
        "\n",
        "rnnmodel.fit(xtrain, ytrain, epochs=epochs, batch_size=batch_size)\n",
        "loss, accuracy = rnnmodel.evaluate(xtrain, ytrain)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = rnnmodel.evaluate(xtest, ytest)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQWSRoLYKQez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRU model\n",
        "grumodel = Sequential()\n",
        "grumodel.add(layers.Embedding(input_dim=vocab_size, output_dim=50, input_length=maxlen))\n",
        "grumodel.add(layers.GRU(units=50))\n",
        "grumodel.add(layers.Dense(2, activation='softmax'))\n",
        "grumodel.compile(optimizer='adam',\n",
        "              loss=losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "grumodel.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y31pzNlCdfaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grumodel.fit(xtrain, ytrain, epochs=epochs, batch_size=batch_size)\n",
        "loss, accuracy = grumodel.evaluate(xtrain, ytrain, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = grumodel.evaluate(xtest, ytest, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRLScNGLSSkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(layers.Embedding(input_dim=vocab_size, output_dim=50, input_length=maxlen))\n",
        "lstm_model.add(layers.LSTM(units=50))\n",
        "lstm_model.add(layers.Dense(2, activation='softmax'))\n",
        "lstm_model.compile(optimizer='adam',\n",
        "              loss=losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "lstm_model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfn1bdX9d6MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_model.fit(xtrain, ytrain, epochs=epochs, batch_size=batch_size)\n",
        "loss, accuracy = lstm_model.evaluate(xtrain, ytrain, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = lstm_model.evaluate(xtest, ytest, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advHR6bGXyZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}